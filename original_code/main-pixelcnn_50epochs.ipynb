{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: data\\mnist\n",
      "WARNING:tensorflow:From <ipython-input-1-e2b8794d45bd>:66: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\mnist\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data\\mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Building pixel_cnn starts!\n",
      "Building conv_inputs\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "[conv2d_a] conv_inputs : Placeholder:0 (?, 28, 28, 1) -> conv_inputs/add:0 (?, 28, 28, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 3 and 16 for 'CONV0/add' (op: 'Add') with input shapes: [?,28,28,3], [?,28,28,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 3 and 16 for 'CONV0/add' (op: 'Add') with input shapes: [?,28,28,3], [?,28,28,16].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e2b8794d45bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e2b8794d45bd>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStatistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Caltech\\pixel-rnn-tensorflow\\original_code\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, height, width, channel)\u001b[0m\n\u001b[0;32m     78\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"pixel_cnn\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mscope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'CONV%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml_hid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_hid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wrong type of model: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Caltech\\pixel-rnn-tensorflow\\original_code\\ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(inputs, num_outputs, kernel_shape, mask_type, strides, padding, activation_fn, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, scope)\u001b[0m\n\u001b[0;32m    149\u001b[0m           tf.float32, biases_initializer, biases_regularizer)\n\u001b[0;32m    150\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outputs_plus_b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;31m# Mayank + Alycia - res in pixelCNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    308\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m--> 310\u001b[1;33m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 3 and 16 for 'CONV0/add' (op: 'Add') with input shapes: [?,28,28,3], [?,28,28,16]."
     ]
    }
   ],
   "source": [
    "import os\n",
    "# CHANGE: remove logger/logging\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *\n",
    "from network import Network\n",
    "from statistic import Statistic\n",
    "\n",
    "import network\n",
    "import statistic\n",
    "import ops\n",
    "import utils\n",
    "\n",
    "# network \n",
    "# CHANGE: replaced flags with variables\n",
    "model = \"pixel_cnn\"\n",
    "batch_size = 100\n",
    "hidden_dims = 16\n",
    "recurrent_length = 7\n",
    "out_hidden_dims = 32\n",
    "out_recurrent_length = 2\n",
    "use_residual = False\n",
    "\n",
    "# training\n",
    "max_epoch = 50 #100000\n",
    "test_step = 100\n",
    "save_step = 1000\n",
    "learning_rate = 1e-3\n",
    "grad_clip = 1\n",
    "use_gpu = True\n",
    "\n",
    "# data\n",
    "data = \"mnist\"\n",
    "data_dir = \"data\"\n",
    "sample_dir = \"samples\"\n",
    "\n",
    "# Debug\n",
    "is_train = True \n",
    "display = False\n",
    "log_level = \"INFO\"\n",
    "random_seed = 123\n",
    "\n",
    "# random seed\n",
    "tf.set_random_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "all_train_err = []\n",
    "all_test_err = []\n",
    "\n",
    "def main(_):\n",
    "    model_dir = \"model\"\n",
    "    \n",
    "    DATA_DIR = os.path.join(data_dir, data)\n",
    "    SAMPLE_DIR = os.path.join(sample_dir, data, model_dir)\n",
    "\n",
    "    check_and_create_dir(DATA_DIR)\n",
    "    #check_and_create_dir(SAMPLE_DIR)\n",
    "    SAMPLE_DIR = 'sample'\n",
    "\n",
    "    # 0. prepare datasets\n",
    "    if data == \"mnist\":\n",
    "        from tensorflow.examples.tutorials.mnist import input_data\n",
    "        mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "\n",
    "        next_train_batch = lambda x: mnist.train.next_batch(x)[0]\n",
    "        next_test_batch = lambda x: mnist.test.next_batch(x)[0]\n",
    "\n",
    "        height, width, channel = 28, 28, 1\n",
    "\n",
    "        train_step_per_epoch = int(mnist.train.num_examples / batch_size)\n",
    "        test_step_per_epoch = int(mnist.test.num_examples / batch_size)\n",
    "    elif data == \"cifar\":\n",
    "        from cifar10 import IMAGE_SIZE, inputs\n",
    "\n",
    "        maybe_download_and_extract(DATA_DIR)\n",
    "        images, labels = inputs(eval_data=False,\n",
    "            data_dir=os.path.join(DATA_DIR, 'cifar-10-batches-bin'), batch_size=batch_size)\n",
    "\n",
    "        height, width, channel = IMAGE_SIZE, IMAGE_SIZE, 3\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        network = Network(sess, height, width, channel)\n",
    "\n",
    "        stat = Statistic(sess, data, model_dir, tf.trainable_variables(), test_step)\n",
    "        stat.load_model()\n",
    "\n",
    "        if is_train:\n",
    "            print(\"Training starts!\")\n",
    "\n",
    "            initial_step = stat.get_t() if stat else 0\n",
    "            iterator = trange(max_epoch, ncols=70, initial=initial_step)\n",
    "\n",
    "            for epoch in iterator:\n",
    "                # 1. train\n",
    "                total_train_costs = []\n",
    "                for idx in range(train_step_per_epoch):\n",
    "                    images = binarize(next_train_batch(batch_size)).reshape([batch_size, height, width, channel])\n",
    "\n",
    "                    cost = network.test(images, with_update=True)\n",
    "                    total_train_costs.append(cost)\n",
    "\n",
    "                # 2. test\n",
    "                total_test_costs = []\n",
    "                for idx in range(test_step_per_epoch):\n",
    "                    images = binarize(next_test_batch(batch_size)).reshape([batch_size, height, width, channel])\n",
    "\n",
    "                    cost = network.test(images, with_update=False)\n",
    "                    total_test_costs.append(cost)\n",
    "\n",
    "                avg_train_cost, avg_test_cost = np.mean(total_train_costs), np.mean(total_test_costs)\n",
    "\n",
    "                stat.on_step(avg_train_cost, avg_test_cost)\n",
    "                print(\"Epoch: {}\".format(epoch))\n",
    "                print(\"train l: {}, test l: {}\".format(avg_train_cost, avg_test_cost))\n",
    "                print()\n",
    "                all_train_err.append(avg_train_cost)\n",
    "                all_test_err.append(avg_test_cost)\n",
    "                print(\"TRAIN ERR: {}\".format(all_train_err))\n",
    "                print(\"TEST ERR: {}\".format(all_test_err))\n",
    "                \n",
    "            iterator.set_description(\"train l: %.3f, test l: %.3f\" % (avg_train_cost, avg_test_cost))\n",
    "\n",
    "            # 3. generate samples\n",
    "            samples = network.generate()\n",
    "            save_images(samples, height, width, 10, 10,\n",
    "                directory=SAMPLE_DIR, prefix=\"epoch_%s\" % epoch)\n",
    "\n",
    "        else:\n",
    "            print(\"Image generation starts!\")\n",
    "\n",
    "            samples = network.generate()\n",
    "            save_images(samples, height, width, 10, 10, directory=SAMPLE_DIR)\n",
    "            \n",
    "        print('Errors:')\n",
    "        print(avg_train_cost)\n",
    "        print(avg_test_cost)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixelcnn, 50 epochs\n",
    "train_err = [0.24605496227741241, 0.13720448315143585, \\\n",
    "             0.1365453600883484, 0.13613757491111755, \\\n",
    "             0.13572151958942413, 0.1353251338005066, \\\n",
    "             0.135013148188591, 0.13462430238723755, \\\n",
    "             0.1343553215265274, 0.13414210081100464, \\\n",
    "             0.1340470016002655, 0.13391567766666412, \\\n",
    "             0.13378024101257324, 0.13375551998615265, \\\n",
    "             0.1336555927991867, 0.1336013525724411, \\\n",
    "             0.13360364735126495, 0.13359662890434265, \\\n",
    "             0.13349081575870514, 0.13346029818058014, \\\n",
    "             0.13339351117610931, 0.13342663645744324, \\\n",
    "             0.13331356644630432, 0.13333041965961456, \\\n",
    "             0.1333276927471161, 0.13332553207874298, \\\n",
    "             0.13324187695980072, 0.1332942545413971, \\\n",
    "             0.13323001563549042, 0.1333010345697403, \\\n",
    "             0.13326437771320343, 0.1332249641418457, \n",
    "             0.13320469856262207, 0.1331661492586136, \\\n",
    "             0.13314370810985565, 0.13312095403671265, \\\n",
    "             0.13313663005828857, 0.13308535516262054, \\\n",
    "             0.13309639692306519, 0.13304206728935242, \\\n",
    "             0.13310347497463226, 0.13306356966495514, \n",
    "             0.1330186277627945, 0.13307428359985352, \\\n",
    "             0.13307270407676697, 0.133034810423851, \\\n",
    "             0.1330339014530182, 0.13304530084133148, \\\n",
    "             0.13297995924949646, 0.1329963058233261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixelcnn, 50 epochs\n",
    "test_err = [0.13751590251922607, 0.13724683225154877, \\\n",
    "            0.13562853634357452, 0.1356244683265686, \\\n",
    "            0.13565725088119507, 0.13435082137584686, \\\n",
    "            0.13500544428825378, 0.13368146121501923, \\\n",
    "            0.1336456537246704, 0.1330556422472,\\\n",
    "            0.13352327048778534, 0.1328164041042328, \\\n",
    "            0.1330333799123764, 0.13277201354503632, \\\n",
    "            0.13301503658294678, 0.13400420546531677, \\\n",
    "            0.13316503167152405, 0.1324576586484909, \\\n",
    "            0.13256293535232544, 0.13306891918182373, \\\n",
    "            0.13233691453933716, 0.13263799250125885, \\\n",
    "            0.13226664066314697, 0.13297809660434723, \\\n",
    "            0.1324387788772583, 0.1322643756866455, \\\n",
    "            0.13372784852981567, 0.13228580355644226, \\\n",
    "            0.13224899768829346, 0.1326654553413391, \\\n",
    "            0.1323050856590271, 0.1332075595855713, \n",
    "            0.13247069716453552, 0.13256895542144775, \\\n",
    "            0.13241930305957794, 0.13304497301578522, \\\n",
    "            0.13239020109176636, 0.1328936219215393, \\\n",
    "            0.1331167072057724, 0.13231536746025085, \\\n",
    "            0.13275370001792908, 0.1323421448469162, \n",
    "            0.13244043290615082, 0.13282164931297302,\\\n",
    "            0.13217896223068237, 0.13308286666870117, \\\n",
    "            0.1321239024400711, 0.13216844201087952, \\\n",
    "            0.13284295797348022, 0.1322878897190094]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.array([i for i in range(50)])\n",
    "y1 = np.array(train_err)\n",
    "\n",
    "_ = plt.plot(x, y1)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelCNN: Train Error vs. Epochs\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array(test_err)\n",
    "\n",
    "_ = plt.plot(x, y2)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelCNN: Test Error vs. Epochs\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x, y1)\n",
    "_ = plt.plot(x, y2)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelCNN: Error vs. Epochs\")\n",
    "_ = plt.legend(['Train Error', 'Test Error'], loc='upper right')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x[1:], y1[1:])\n",
    "_ = plt.plot(x[1:], y2[1:])\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelCNN: Error vs. Epochs (Starting from First Epoch)\")\n",
    "_ = plt.legend(['Train Error', 'Test Error'], loc='upper right')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PixelRNN (30 epochs)\n",
    "Run on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_err = [0.33173471689224243, 0.2706405222415924, \\\n",
    "                 0.26856547594070435, 0.2672751247882843, \\\n",
    "                 0.26637789607048035, 0.2656841278076172, \\\n",
    "                 0.2653653621673584, 0.26494771242141724, \\\n",
    "                 0.26459965109825134, 0.26446565985679626, \\\n",
    "                 0.2643096446990967, 0.26410093903541565, \\\n",
    "                 0.26406511664390564, 0.26395508646965027, \\\n",
    "                 0.2638961970806122, 0.26377028226852417, \\\n",
    "                 0.2637140154838562, 0.26363253593444824, \\\n",
    "                 0.26364585757255554, 0.26362985372543335, \\\n",
    "                 0.2635285258293152, 0.2634545862674713, \\\n",
    "                 0.26345521211624146, 0.26345980167388916, \\\n",
    "                 0.26338160037994385, 0.26338672637939453, \\\n",
    "                 0.2633686661720276, 0.26338306069374084, \\\n",
    "                 0.26334333419799805, 0.26338595151901245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_test_err = [0.26983755826950073, 0.2678973078727722, \\\n",
    "                0.2721490263938904, 0.2657012641429901, \\\n",
    "                0.2675149440765381, 0.26663628220558167, \\\n",
    "                0.26623988151550293, 0.2671581208705902, \\\n",
    "                0.26454776525497437, 0.2660485506057739, \\\n",
    "                0.2635952830314636, 0.2630610764026642, \\\n",
    "                0.2630372941493988, 0.26368436217308044, \\\n",
    "                0.2637206017971039, 0.26339274644851685, \\\n",
    "                0.263009637594223, 0.2633385956287384, \\\n",
    "                0.2630334794521332, 0.262796014547348, \\\n",
    "                0.2626510560512543, 0.2628699839115143, \\\n",
    "                0.2627430558204651, 0.2628183662891388, \\\n",
    "                0.26300930976867676, 0.26286861300468445, \\\n",
    "                0.26275765895843506,  0.26291176676750183,\\\n",
    "                0.26294758915901184,  0.2625179588794708]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([i for i in range(30)])\n",
    "y1 = np.array(rnn_train_err)\n",
    "\n",
    "_ = plt.plot(x, y1)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelRNN: Train Error vs. Epochs\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array(rnn_test_err)\n",
    "\n",
    "_ = plt.plot(x, y2)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelRNN: Test Error vs. Epochs\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x, y1)\n",
    "_ = plt.plot(x, y2)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelRNN: Error vs. Epochs\")\n",
    "_ = plt.legend(['Train Error', 'Test Error'], loc='upper right')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x[1:], y1[1:])\n",
    "_ = plt.plot(x[1:], y2[1:])\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Error (Cross Entropy)\")\n",
    "_ = plt.title(\"PixelRNN: Error vs. Epochs (Starting from First Epoch)\")\n",
    "_ = plt.legend(['Train Error', 'Test Error'], loc='upper right')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
